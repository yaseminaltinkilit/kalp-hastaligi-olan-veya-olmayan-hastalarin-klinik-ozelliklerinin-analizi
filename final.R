install.packages("skewness")
library(tree)
library(skewness)
library(readr)
library(corrplot)
library(caret)
library(tidyverse)
library(magrittr)
library(olsrr)
library(car)
library(corrplot)
library(nortest)
library(ISLR)
library(Hmisc)
library(caret)
library(dplyr)
library(ModelMetrics)
library(lmtest)
library(moments)
library(bestNormalize) # normalization 
library(MASS)
library(psych) 
library(mvnTest) # perform multivariate normality test
library(tree) # perform regression and decision tree
library(randomForest) # perform random forest
library(rpart)  # performing regression trees
library(rpart.plot)  # plotting regression trees
library(ipred)       # bagging
library(olsrr)
library(kmed)
heart -> heart

#age: HastanÄ±n yaÅŸÄ±
#sex: HastanÄ±n cinsiyeti (1 = erkek, 0 = kadÄ±n)
#cp: Chest pain (Kalp aÄŸrÄ±sÄ±) (0 = asymptomatic, 1 = atypical angina, 2 = non-anginal pain, 3 = typical angina)
#trestbps: Resting blood pressure (dinlenme kan basÄ±ncÄ±)
#chol: Serum cholesterol (kolestrol)
#fbs: Fasting blood sugar (aynaÃ§ kan ÅŸekeri) (1 = true, 0 = false)
#restecg: Resting electrocardiographic results (dinlenme elektrokardiyografik sonuÃ§larÄ±)
#thalach: Maximum heart rate achieved (maksimum atÄ±m hÄ±zÄ±)
#exang: Exercise induced angina (Egzersiz nedenli anjina) (1 = yes, 0 = no)
#oldpeak: ST depression induced by exercise relative to rest (Egzersiz nedenli ST depresyonu)
#slope: The slope of the peak exercise ST segment (Egzersiz ST segmentin eÄŸimi)
#ca: Number of major vessels (0-3) colored by flourosopy (BÃ¼yÃ¼k damarlarÄ±n sayÄ±sÄ±)
#thal: 3 = normal; 6 = fixed defect; 7 = reversable defect (normal, sabit kusur, tersine Ã§evrilebilir kusur)
#target: Diagnosis of heart disease (1 = yes, 0 = no) (Kalp hastalÄ±ÄŸÄ± tanÄ±sÄ±)

head(heart)
str(heart)

#heart datasÄ±nda class sÃ¼tununu 0 olanlarÄ± 0 diÄŸer deÄŸerleri 1 olarak tanÄ±mlamak iÃ§in;

for (i in 1:nrow(heart)) {
  if(heart$class[i] == 0) {
    heart$class[i] <- 0
  } else {
    heart$class[i] <- 1
  }
}

heart

#datayÄ± incelediÄŸimde sex,fbs,exang kategorik deÄŸiÅŸkenleri factore dÃ¶nÃ¼ÅŸtÃ¼rÃ¼yoruz;
heart$class <- as.factor(heart$class)
heart$sex <- as.factor(heart$sex)
heart$fbs <- as.factor(heart$fbs)
heart$exang <- as.factor(heart$exang)

dim(heart)
str(heart)
################TanÄ±mlayÄ±cÄ± Ä°statistik################################################################
# TanÄ±mlayÄ±cÄ± Ä°statistik:

# eksik deÄŸer gÃ¶zlemi
sum(is.na(heart))

#eksik deÄŸer bulunmamaktadÄ±r.

summary(heart)

#TÃ¼m numeric deÄŸerlere baktÄ±ÄŸÄ±mÄ±zda mean ve medyan arasÄ±nda bÃ¼yÃ¼k farklÄ±lÄ±klar olmadÄ±ÄŸÄ± gÃ¶zlemlenmiÅŸtr. Buna gÃ¶re Ã§arpÄ±klÄ±k yok gibi gÃ¶zÃ¼kÃ¼yor. GÃ¶rsel deÄŸerlerle daha net sonuÃ§lara varÄ±labilinir.
#class baÄŸÄ±mlÄ± deÄŸiÅŸkenimiz. Kalp hastalÄ±ÄŸÄ± tanÄ±sÄ± 0 olanlar yok 1 olanlar var.

par(mfrow = c(1,4))

boxplot(heart$age, col = "tomato", main = "age")
boxplot(heart$trestbps, col = "tomato", main = "trestbps")
boxplot(heart$chol, col = "tomato", main = "chol")
boxplot(heart$thalach, col = "tomato", main = "thalach")

#trestbps(kan basÄ±ncÄ±), chol(kolestrol) ve thalach(maksimum kalp atÄ±ÅŸ hÄ±zÄ±) alanlarÄ±nda outlier var gibi duruyor. GerÃ§ekten etkilimi diye ilerleyen aÅŸamalarda inceleyeceÄŸim.
# histogram ve normallik hipotez heartleri daha doÄŸru yorum yapÄ±lmasÄ±na olanak saÄŸlayabilir.

dev.off()

#korelasyona bakÄ±yoruz.

corr <- cor(heart[,c("age","trestbps","chol","oldpeak","thalach","ca","class")])
corr
corrplot(corr)


#test train diye ayÄ±rÄ±yorum.

smp_size <- floor(0.70 * nrow(heart)) 
set.seed(2022900075) 
train_ind <- sample(nrow(heart), size = smp_size, replace = FALSE)
train <- heart[train_ind, ]
test <- heart[-train_ind, ]

#######SÄ±nÄ±flandÄ±rma ve karar aÄŸaÃ§larÄ±#########

treeclass <- tree(class~. , train )
summary(treeclass ) # error rate Ã¶nemli

# Toplam 18 terminal node ile aÄŸaÃ§ oluÅŸturulmuÅŸ.
# Residual mean deviance 0.463 olarak dikkat Ã§ekiyor.
# Error rate 0.11 gibi yÃ¼ksek sayÄ±labilecek bir deÄŸer almÄ±ÅŸ.

plot(treeclass )
text(treeclass ,pretty =0)

# KÃ¶k dÃ¼ÄŸÃ¼m(root node) hisofprematurelabor'un 1,2 ve 3 olmasÄ± olarak saptanmÄ±ÅŸ.

set.seed(3)
cv.heart <- cv.tree(treeclass ,FUN=prune.misclass )
cv.heart


treeclass
set.seed(3)
cv.treeclass <- cv.tree(treeclass ,FUN=prune.misclass )
cv.treeclass
par(mfrow=c(1,2))
plot(cv.treeclass$size ,cv.treeclass$dev ,type="b")

# Grafik de incelendiÄŸinde size'Ä±n 7 olduÄŸu noktada deviance'de belirgin azalmalar dikkat Ã§ekmekte. Bu sebeple size 2 olarak seÃ§ilerek devam edilecektir.

### Budama #####
prune.treeclass <- prune.misclass (treeclass,best=7)
summary(prune.treeclass)


prune.treeclass2 <- prune.misclass (treeclass,best=12)
summary(prune.treeclass2)

#12 yi seÃ§iyorum hata oranÄ± iyi sonuÃ§ verdiÄŸi iÃ§in.
# Budama sonrasÄ± yalnÄ±zca iki node ile model residual mean deviance'Ä±nÄ±n 0.81 olarak bir artÄ±ÅŸ gÃ¶stermiÅŸ gÃ¶rÃ¼nÃ¼yor.
# Error rate'de de 0.14 olarak artÄ±ÅŸ gÃ¶rÃ¼lmekte.

dev.off()
plot(prune.treeclass2 )
text(prune.treeclass2 ,pretty =0)
#yorumla.


### Budama Ã–ncesi Tahminler ###

### Train

classtree.pred <- predict(treeclass ,train ,type="class")

caret::confusionMatrix(classtree.pred, train$class)

# Accuracy Rate : 0.89
# Sensitivity : 0.88
# Specificity : 0.89

### Test

classtree.predtest <- predict(treeclass, test, type = "class")

caret::confusionMatrix(classtree.predtest, test$class)

# Accuracy Rate : 0.73
# Sensitivity : 0.70
# Specificity : 0.77

### Budama SonrasÄ± Tahminler ###

### Train

prunedtree.pred <- predict(prune.treeclass2 ,train ,type="class")

caret::confusionMatrix(prunedtree.pred, train$class)

# Accuracy Rate : 0.8841
# Sensitivity : 0.8364
# Specificity : 0.9381

### Test

prunedtree.predtest <- predict(prune.treeclass2, test, type = "class")

caret::confusionMatrix(prunedtree.predtest, test$class)

# Accuracy Rate : 0.7222
# Sensitivity : 0.6600
# Specificity : 0.8000

# Budama sonrasÄ± sÄ±nÄ±flandÄ±rmanÄ±n performansÄ±nÄ±n arttÄ±ÄŸÄ±nÄ± accuracy rate, sensivity ve specificity deÄŸerleri incelenerek kolaylÄ±kla gÃ¶zlemlenebilir.
# Hem budanmÄ±ÅŸ, hem de orijinal aÄŸacÄ±n confusion matrix'i incelendiÄŸinde ise her ikisinde de test verisinde performansÄ±n dÃ¼ÅŸtÃ¼ÄŸÃ¼nÃ¼ fark ediyoruz -ki bu hiÃ§ istediÄŸimiz bir ÅŸey deÄŸil.


## BAGGING ####


bag <- randomForest(class~. ,data=train, mtry=13,importance=TRUE)

bag$importance
varImpPlot(bag)

# DeÄŸiÅŸkenlerin Ã¶nemlerine bakÄ±ldÄ±ÄŸÄ±nda;

# Mean decrease accuracy incelendiÄŸinde en Ã§ok cp, ardÄ±ndan oldpeak,thai,thalach, ca sÄ±ralamasÄ± gÃ¶rÃ¼lmekte.
# Gini deÄŸerlerine bakÄ±ldÄ±ÄŸÄ±nda ise cp, oldpeak,hal sÄ±ralamasÄ± dikkat Ã§ekiyor


### Train

baggintrain <- predict(bag ,train ,type="class")

caret::confusionMatrix(baggintrain, train$class)

# Accuracy Rate : 1
# Sensitivity : 1
# Specificity : 1

### Test

baggintest <- predict(bag, test, type = "class")

caret::confusionMatrix(baggintest, test$class)

# Accuracy Rate : 0.80
# Sensitivity : 0.88
# Specificity : 0.70

# Hem budanmÄ±ÅŸ, hem de orijinal aÄŸacÄ±n confusion matrix'i incelendiÄŸinde ise her ikisinde de test verisinde performansÄ±n dÃ¼ÅŸtÃ¼ÄŸÃ¼nÃ¼ fark ediyoruz -ki bu hiÃ§ istediÄŸimiz bir ÅŸey deÄŸil.
# Train verisinde %100'lÃ¼k baÅŸarÄ± ilgi Ã§ekici gÃ¶rÃ¼nÃ¼yor.

#BaÅŸarÄ± oranÄ± 0.84 olarak gÃ¶zlemlenmiÅŸtir. 

##RANDOM FORREST####

rf <- randomForest(class~. ,data=train, mtry=4,importance=TRUE)

rf$importance
varImpPlot(rf)

# DeÄŸiÅŸkenlerin Ã¶nemlerine bakÄ±ldÄ±ÄŸÄ±nda;

# Mean decrease accuracy incelendiÄŸinde en Ã§ok cp, ardÄ±ndan thal, ca, oldpeak, ca sÄ±ralamasÄ± gÃ¶rÃ¼lmekte.
# Gini deÄŸerlerine bakÄ±ldÄ±ÄŸÄ±nda ise cp, thalach, oldpeak sÄ±ralamasÄ± dikkat Ã§ekiyor
# Baggin ile oldukÃ§a paralel olduÄŸunu sÃ¶ylemek yanlÄ±ÅŸ olmaz.

# Test verilerinde tahmin yapma
predrf <- predict(rf, train)
caret::confusionMatrix(predrf, train$class)

# Accuracy Rate : 1
# Sensitivity : 1
# Specificity : 1

# Tahmin doÄŸruluÄŸunu hesaplama
predrf_test <- predict(rf, test)
caret::confusionMatrix(predrf_test, test$class)

# Accuracy Rate : 0.8222
# Sensitivity : 0.88
# Specificity : 0.75


##Lojistik Regresyon####
# Lojistik regresyon modeli oluÅŸturma

logmodel1 <- glm(class ~ ., data = train, family = binomial(link = "logit"))
summary(logmodel1)

# katsayÄ± yorumu

# BaÄŸÄ±msÄ±z deÄŸiÅŸkenin deÄŸerini bir birim arttÄ±rdÄ±ÄŸÄ±mÄ±zda tahmin deÄŸerindeki deÄŸiÅŸikliÄŸi
# belirlemek iÃ§in Ã¶nce log(odds) formulÃ¼nde her iki tarafa exp fonksiyonu uygulanÄ±r.

# AnlamlÄ± deÄŸiÅŸkenlerin katsayÄ± yorumu:


exp(1.587495) # kalp rahatsÄ±zlÄ±ÄŸÄ± olan kiÅŸilerin sexTRUE deÄŸiÅŸkendeki 1 birimlik artÄ±ÅŸ odds oranÄ±nÄ± 4.89 kat deÄŸiÅŸtirir.
exp(2.033127)  # kalp rahatsÄ±zlÄ±ÄŸÄ± olan kiÅŸilerin cp2 deÄŸiÅŸkenindeki bir birimlik artÄ±ÅŸ odds oranÄ±nÄ± 7.63 kat deÄŸiÅŸtirir
exp(2.720513)  # kalp rahatsÄ±zlÄ±ÄŸÄ± olan kiÅŸilerin cp4 deÄŸiÅŸkenindeki bir birimlik artÄ±ÅŸ odds oranÄ±nÄ± 15.18 kat deÄŸiÅŸtirir
exp(0.031994) # kalp rahatsÄ±zlÄ±ÄŸÄ± olan kiÅŸilerin trestbps deÄŸiÅŸkenindeki 1 birimlik artÄ±ÅŸ odds oranÄ±nÄ± 1.03 kat deÄŸiÅŸtirir.
exp(-0.029842) # kalp rahatsÄ±zlÄ±ÄŸÄ± olan kiÅŸilerin thalach deÄŸiÅŸkenindeki 1 birimlik artÄ±ÅŸ odds oranÄ±nÄ± 0.97 kat deÄŸiÅŸtirir.
exp(1.057276) # kalp rahatsÄ±zlÄ±ÄŸÄ± olan kiÅŸilerin ca deÄŸiÅŸkenindeki 1 birimlik artÄ±ÅŸ odds oranÄ±nÄ± 2.87 kat deÄŸiÅŸtirir.
exp(1.162959) # kalp rahatsÄ±zlÄ±ÄŸÄ± olan kiÅŸilerin thal7 deÄŸiÅŸkenindeki 1 birimlik artÄ±ÅŸ odds oranÄ±nÄ± 3.19 kat deÄŸiÅŸtirir.

confint.default(logmodel1)
#katsayÄ±sÄ±na ait %95 lik gÃ¼ven aralÄ±ÄŸÄ± sÄ±fÄ±r deÄŸerini kapsadÄ±ÄŸÄ± iÃ§in H 0 hipotezi red edilemeyerek aÅŸaÄŸÄ±daki deÄŸiÅŸkenlerin
# kalp hastasÄ± olma etkisinin istatistiksel olarak anlamlÄ± olmadÄ±ÄŸÄ±na karar verilir.

# age, cp3, chol,fbsTRUE, restecg1,restecg2,thalach,exangTRUE,oldpeak, slope2, slope3,thal6

# odds iÃ§in gÃ¼ven aralÄ±ÄŸÄ±
# EÄŸer odds oran deÄŸerine ait gÃ¼ven aralÄ±ÄŸÄ± 1 deÄŸerini iÃ§ermiyor ise H 0 hipotezi red edilerek ilgili katsayÄ±nÄ±n istatistiksel olarak anlamlÄ± olduÄŸuna karar verilir.
odds.confint <- exp(confint.default(logmodel1))
odds.confint
#yorumlanacak
# anlamsÄ±z katsayÄ±lar: 
# age,cp3,chol,fbsTRUE,restecg1,restecg2,thalach,exangTRUE,oldpeak,slope2,slope3

# anlamlÄ± katsayÄ±lar:
#sexTRUE,cp2,cp4,trestbps,thal6,thal7

# YaÅŸÄ± 1 birim bÃ¼yÃ¼k olankalp hastasÄ±nÄ±n oddsu %95 gÃ¼venle bir yaÅŸ kÃ¼Ã§Ã¼k olanÄ±n 0.93 katÄ± ile 1.04 katÄ± arasÄ±nda deÄŸer alÄ±r.
#  birim bÃ¼yÃ¼k olan bir kiÅŸinin dÃ¼ÅŸÃ¼k aÄŸÄ±rlÄ±klÄ± Ã§ocuk doÄŸurma oddsu %95 gÃ¼venle bir birim az olanÄ±n 1.39 katÄ± ile 22.28 katÄ± arasÄ±nda deÄŸer alÄ±r.
# Smoking bir birim bÃ¼yÃ¼k olan bir kiÅŸinin dÃ¼ÅŸÃ¼k aÄŸÄ±rlÄ±klÄ± Ã§ocuk doÄŸurma oddsu %95 gÃ¼venle bir birim az olanÄ±n 1.03 katÄ± ile 7.40 katÄ± arasÄ±nda deÄŸer alÄ±r.
# Hisofprematurelabor1 bir birim bÃ¼yÃ¼k olan bir kiÅŸinin dÃ¼ÅŸÃ¼k aÄŸÄ±rlÄ±klÄ± Ã§ocuk doÄŸurma oddsu %95 gÃ¼venle bir birim az olanÄ±n 2.02 katÄ± ile 24.69 katÄ± arasÄ±nda deÄŸer alÄ±r.
# Hypertension1 bir birim bÃ¼yÃ¼k olan bir kiÅŸinin dÃ¼ÅŸÃ¼k aÄŸÄ±rlÄ±klÄ± Ã§ocuk doÄŸurma oddsu %95 gÃ¼venle bir birim az olanÄ±n 1.24 katÄ± ile 31.86 katÄ± arasÄ±nda deÄŸer alÄ±r.

# modelin anlamlÄ±lÄ±ÄŸÄ±

#ğ» 0 : ğ›½ 1 = ğ›½ 2 = â‹¯ = ğ›½ ğ‘˜ = 0
# ğ» 1 : ğ¸ğ‘› ğ‘ğ‘§ğš¤ğ‘›ğ‘‘ğ‘ğ‘› ğ‘ğ‘–ğ‘Ÿ ğ›½ ğ‘— â‰  0

summary(logmodel1)

# G= Null deviance-Residual Deviance
286.15 -135.72

1-pchisq(150.43,206-188) 

#p deÄŸeri 0 Ã§Ä±kÄ±yor 

# H 0 :Î² AGE = 0 hipotezi red edilir.
# BaÄŸÄ±mlÄ± deÄŸiÅŸkenlerin lbw deÄŸiÅŸkenini aÃ§Ä±klamada etkili olduÄŸunu sÃ¶yleyebilecek yeterli istatistiksel kanÄ±tÄ±mÄ±z bulunmaktadÄ±r.



ppred <- fitted(logmodel1)
summary(ppred)

# Ä°lk olarak threshold deÄŸeri medyan deÄŸeri kabul edilecek tahminlerde bulunulacaktÄ±r.
threshold <- 0.355467
ppred[ppred > threshold] <- 1
ppred[ppred < threshold] <- 0
ppred <- as.factor(ppred)
caret::confusionMatrix(ppred, train$class)
# Accuracy Rate : 0.8647
# Sensitivity : 0.8455
# Specificity : 0.8866
### Test
testpred <- predict(logmodel1, newdata = test)
testpred[testpred > threshold] <- 1
testpred[testpred < threshold] <- 0
testpred <- as.factor(testpred)
caret::confusionMatrix(testpred, test$class)
# Accuracy Rate : 0.8222
# Sensitivity : 0.9000
# Specificity : 0.7250

##LINEAR DISCRIMINANT ANALYSIS#####

#sadece numeric deÄŸerleri kullanacaÄŸÄ±z.

# AyrÄ±ÅŸtÄ±rma Analizi, veri setindeki deÄŸiÅŸkenlerin iki veya daha fazla gerÃ§ek gruplara ayrÄ±lmasÄ±nÄ± saÄŸlayan, 
# birimlerin p tane Ã¶zelliÄŸini ele alarak bu birimlerin doÄŸal ortamdaki gerÃ§ek gruplarÄ±na optimal dÃ¼zeyde atanmalarÄ±nÄ± saÄŸlayacak fonksiyonlar tÃ¼reten bir yÃ¶ntemdir.

# Teorik olarak her grubun temel Ã¶zellikleri vardÄ±r. Her grup bu temel Ã¶zelliklerine gÃ¶re tanÄ±mlanÄ±r ve bilinir.
# AyrÄ±ÅŸtÄ±rma Analizinin iki temel gÃ¶revi vardÄ±r.
# GruplarÄ± birbirinden ayÄ±rmayÄ± saÄŸlayan fonksiyonlarÄ± bulmak. (AYIRMA)
# Hesaplanan fonksiyonlar aracÄ±lÄ±ÄŸÄ± ile yeni gÃ¶zlenen bir birimi sÄ±nÄ±flandÄ±rma hatasÄ± minimum olacak ÅŸekilde uygun bir sÄ±nÄ±fa atamaktÄ±r. (SINIFLANDIRMA)

# LDA yÃ¶nteminde bilinen kategorilerin ayrÄ±lmasÄ±nÄ± en Ã¼st dÃ¼zeye Ã§Ä±karmaya Ã§alÄ±ÅŸÄ±r.

# GruplarÄ±n ortalamalarÄ± arasÄ±nda maksimum ayrÄ±mÄ± yapacak ÅŸekilde bileÅŸen belirler.VarsayÄ±mlar: 

# 1. LDA yÃ¶ntemi aÃ§Ä±klayÄ±cÄ± deÄŸiÅŸkenlerin Ã§ok deÄŸiÅŸkenli normal daÄŸÄ±lÄ±ma sahip olduÄŸu varsayÄ±mÄ±na dayanÄ±r.
# 2. DoÄŸrusal LDA her bir grup iÃ§inde deÄŸiÅŸkenlerin k x k boyutlu varyans-kovaryans matrislerinin aynÄ± olduÄŸu varsayar.
# 3. DeÄŸiÅŸkenler arasÄ±nda Ã§oklu doÄŸrusal baÄŸlantÄ± bulunmamalÄ±dÄ±r.
# 4. X matrisi gereÄŸinden fazla ve gereksiz deÄŸiÅŸken iÃ§ermemelidir.

# AyrÄ±ÅŸtÄ±ran bilgi ortalamada deÄŸil varyansta ise LDA baÅŸarÄ±sÄ±z olacaktÄ±r.


# â€¢ EÄŸer gruplar iyi ayrÄ±lmÄ±ÅŸ ise lojistik regresyona gÃ¶re daha duraÄŸan sonuÃ§ verir.
# â€¢ EÄŸer Ã¶rneklem bÃ¼yÃ¼klÃ¼ÄŸÃ¼ kÃ¼Ã§Ã¼k ve aÃ§Ä±klayÄ±cÄ± deÄŸiÅŸkenler normal daÄŸÄ±lÄ±ma sahip ise LDA daha iyi performans gÃ¶steriyor.
# â€¢ EÄŸer baÄŸÄ±mlÄ± deÄŸiÅŸken ikiden fazla sÄ±ralÄ± olmayan kategoriye sahip ise LDA daha iyi sonuÃ§ verir.
# â€¢ LDA ve lojistik regresyon yÃ¶ntemleri doÄŸrusal karar sÄ±nÄ±rlarÄ± verir.
# â€¢ EÄŸer gerÃ§ek sÄ±nÄ±rlar doÄŸrusal ise LDA ve Lojistik regresyon yÃ¶ntemleri iyi performans gÃ¶sterirler.


trainba= train[,c(1,4,5,8,10,14)]
testba= test[,c(1,4,5,8,10,14)]
pairs.panels(trainba[1:5],
             gap=0,
             bg=c("red","orange")[train$class],
             pch=21)
desc=describeBy(train[2:9], train[,1]) # her bir tÃ¼r iÃ§in bakmak skor hesaplamasÄ± iÃ§in gerekli
desc

#thalach, age ve chol arasÄ±ndaki ayrÄ±ÅŸmalar daha belirgin olarak gÃ¶ze Ã§arpÄ±yor.
#oldpeak ile diÄŸer bÃ¼tÃ¼n deÄŸiÅŸkenler arasÄ±nda belirgin bir ayrÄ±m olmuÅŸ.
#chol, age,trestbps arasÄ±ndaki ayrÄ±ÅŸmalar Ã§ok belirgin deÄŸil.

#age ve thalach arasÄ±ndaki korelasyon yÃ¼ksek Ã§Ä±kmÄ±ÅŸtÄ±r.Ã‡oklu baÄŸlantÄ± problemi olabilir.


model_lda <- lda(class~.,data=trainba)
model_lda
model_lda$prior # %kaÃ§ deÄŸer aldÄ±klarÄ±nÄ±

# Birinci doÄŸrusal ayrÄ±ÅŸtÄ±rma fonksiyonu ile %53 oranÄ±nda ayrÄ±ÅŸma saÄŸlanÄ±yor.
#grup ortalamalarÄ±na bakÄ±ldÄ±ÄŸÄ±nda thalach deÄŸiÅŸimindeki ayrÄ±m pair plotta olduÄŸu gibi belirgin bir ÅŸekilde gÃ¶zÃ¼kmektedir.

tahmin_1<-predict(model_lda,trainba)
hist_lda1<-ldahist(data=tahmin_1$x[,1],g=trainba$class) 

#-1 ile 1 ArasÄ±nda iki sÄ±nÄ±fÄ±n birbiriyle Ã¶rtÃ¼ÅŸtÃ¼ÄŸÃ¼ gÃ¶rÃ¼lmektedir. Bu da Ã§ok iyi ayrÄ±ÅŸmanÄ±n saÄŸlanamadÄ±ÄŸÄ±nÄ± bize gÃ¶sterir.

tahmin_1$class # tahmine gÃ¶re sÄ±nÄ±f ayÄ±rmasÄ±
tahmin_1$posterior # gÃ¶zlemlerin gruplara dahil olma olasÄ±lÄ±klarÄ±nÄ± verir. birbirine yakÄ±n olasÄ±lÄ±klarÄ±n deÄŸeri Ã§ok fazla
tahmin_1$x # fonksiyonda gÃ¶zlemlerin aldÄ±ÄŸÄ± deÄŸerleri gÃ¶sterir .histogram karÅŸÄ±laÅŸtÄ±rmasÄ±yla aynÄ± deÄŸerleri alÄ±r

trainba$class <- as.factor(trainba$class)
install.packages("klaR")
library(klaR)
partimat(class ~., data=trainba,method="lda") #  kÄ±rmÄ±zÄ±lar yanlÄ±ÅŸ etiketleme gÃ¶sterir | iyi ayrÄ±ÅŸma yok

#deÄŸiÅŸken Ã§iftlerinin ayrÄ±ÅŸma plotu incelendiÄŸinde en hatalÄ± ayrÄ±ÅŸmanÄ±n chol ve trestbps olarak gÃ¶rÃ¼lmektedir.
#en az olan ise thalach ve oldpeaktir.

##LDA Confusion####

### Train

ldatrain <- predict(model_lda ,trainba)
caret::confusionMatrix(ldatrain$class, trainba$class)

# Accuracy Rate : 0.7536
# Sensitivity : 0.8364
# Specificity : 0.6598

### Test

ldatest <- predict(model_lda ,testba)
caret::confusionMatrix(ldatest$class, testba$class)

# Accuracy Rate : 0.722
# Sensitivity : 0.76
# Specificity : 0.6750

###QUADRATIC DISCRIMINANT ANALYSIS####

# farklÄ± kovaryans matrisine sahip olabilir 
# eÄŸrisel fonksiyonlarla Ã§alÄ±ÅŸÄ±r
# lda'ya gÃ¶re daha esnek olduÄŸu iÃ§in daha dÃ¼ÅŸÃ¼k varyansÄ± vardÄ±r
# eÄŸitim veride gÃ¶zlem sayÄ±sÄ± dÃ¼ÅŸÃ¼kse lda daha mantÄ±klÄ±
# tam tersi durumda qda daha mantÄ±klÄ±

model_qda<-qda(class~.,data=trainba) 

### Train

trainn <- predict(model_qda ,trainba)
caret::confusionMatrix(trainn$class, trainba$class)

# Accuracy Rate : 0.7536
# Sensitivity : 0.8455
# Specificity : 0.6495

### Test

qdatest <- predict(model_qda ,testba)
caret::confusionMatrix(qdatest$class, testba$class)

# Accuracy Rate : 0.7444
# Sensitivity : 0.80
# Specificity : 0.6750

# %74 tahmin oranÄ±  test verisinde daha baÅŸarÄ±lÄ± olmasÄ±nÄ± bekleriz. yeterli baÅŸarÄ± yok. 
library(graphics)
partimat(class~., data=trainba, method="qda")

#oldpeak ve thalach en iyisi lda da Ã¶yle Ã§Ä±kmÄ±ÅŸtÄ±. en kÃ¶tÃ¼sÃ¼ de age ve trestbps Ã§Ä±kmÄ±ÅŸtÄ±r.

###VarsayÄ±m KontrolÃ¼#######
#burayÄ± hiÃ§ anlamadÄ±m!!!!!

# Multivariate Normallik Testleri 

heartba= heart[,c(1,4,5,8,10,14)]
sÄ±fÄ±r <- heartba[heartba$class==0,]
bir <- heartba[heartba$class==1,]

install.packages("mvnTest")
library(mvnTest)
# multivariate normallik testleri 

HZ.test(sÄ±fÄ±r[, c(1:5)])
HZ.test(bir[, c(1:5)])

# data Ã§ok deÄŸiÅŸkenli normal daÄŸÄ±lmÄ±yor. ilk varsayÄ±m saÄŸlanÄ±lamadÄ±


DH.test(sÄ±fÄ±r[, c(1:5)])
DH.test(bir[, c(1:5)])

# ikinci terstten de aynÄ± sonuÃ§ verdi

library(bestNormalize)
library(nortest)



# multivariate normal deÄŸil



### Varyans HomojenliÄŸi Testi

##Assumption Checking of LDA vs. QDA


##http://thatdatatho.com/2018/02/19/assumption-checking-lda-vs-qda-r-tutorial-2/

library(car)
leveneTest(heartba$age ~ as.factor(heartba$class), heartba) # homojen, varyans homojenliÄŸi testine gÃ¶re 0.05 anlamlÄ±lÄ±k dÃ¼zeyinde h0 age deÄŸiÅŸkeni iÃ§in sÄ±nÄ±flara gÃ¶re varyans homojenliÄŸi olduÄŸu hipotezi reddedilebilir. 
leveneTest(heartba$trestbps ~ as.factor(heartba$class), heartba) # homojen deÄŸil,reddedilemez
leveneTest(heartba$chol ~ as.factor(heartba$class), heartba) # homojen deÄŸil,reddedilemez.
leveneTest(heartba$thalach ~ as.factor(heartba$class), heartba) # homojen, reddedilir
leveneTest(heartba$oldpeak ~ as.factor(heartba$class), heartba) #homojen, reddedilemez.


#We are using the BoxM test in order to check our assumption of homogeneity of variance-covariance matrices.
#H_o = Covariance matrices of the outcome variable are equal across all groups
#H_a = Covariance matrices of the outcome variable are different for at least one group

install.packages("heplots")
library(heplots)

boxm <- heplots::boxM(heartba[, c(1:5)], heartba$class) 
boxm # p-value 0.05'ten kÃ¼Ã§Ã¼k Ã§Ä±ktÄ±ÄŸÄ± iÃ§in baÄŸÄ±msÄ±z deÄŸiÅŸkenlerin kovaryans matrislerinin eÅŸit olduÄŸu varsayÄ±mÄ± reddedilemez


###Yapay Sinir AÄŸlarÄ±####

# neuralnet paketini yÃ¼kle
install.packages("neuralnet")

# paketi yÃ¼klÃ¼ olduÄŸunu doÄŸrula
library(neuralnet)

trainba= train[,c(1,4,5,8,10,14)]
testba= test[,c(1,4,5,8,10,14)]


# yapay sinir aÄŸÄ±nÄ± oluÅŸtur
model_nn <- neuralnet(class~.,data=trainba)

tahmin_2<-predict(model_nn,trainba)
trainba$class <- as.factor(trainba$class)


# yapay sinir aÄŸÄ±nÄ± eÄŸit
nn_fit <- compute(model_nn, trainba)

modelnn <- train(class ~., data = trainba, method = "nnet",
               trControl = trainControl(method = "cv", number = 5),
               tuneLength = 10)
# Modeli test etme
predictions <- predict(modelnn, testba)
confusionMatrix(predictions, testba$class)

caret::confusionMatrix(qdatest$class, testba$class)

#accuracy: 0.67
#sensitivity: 0.72
#specificity: 0.60

## ROC####
install.packages("ROCR")
library(ROCR)

predct <- prediction(as.numeric(as.vector(prunedtree.predtest)), test$class)
predbag <- prediction(as.numeric(as.vector(baggintest)), test$class)
predrf <- prediction(as.numeric(as.vector(predrf_test)), test$class)
predlr <- prediction(as.numeric(as.vector(testpred)), test$class)
predlda <- prediction(as.numeric(as.vector(ldatest$class)), testba$class)
predqda <- prediction(as.numeric(as.vector(qdatest$class)), testba$class)
prednn <- prediction(as.numeric(as.vector(predictions)), test$class)
perfct <- performance( predct, "tpr", "fpr" )
perfbag <- performance(predbag, "tpr", "fpr")
perfrf <- performance(predrf, "tpr", "fpr")
perflr <- performance(predlr, "tpr", "fpr")
perflda <- performance(predlda, "tpr", "fpr")
perfqda <- performance(predqda, "tpr", "fpr")
perfnn <- performance(prednn, "tpr", "fpr")

plot(perfct, col = "darkcyan", lwd = 3)
plot(perfbag, add = TRUE, col = "darksalmon", lwd = 3)
plot(perfrf, add=T, col = "burlywood3", lwd = 3)
plot(perflda, add = TRUE, col = "coral1", lwd = 3)
plot(perfqda,add=T, col = "darkgrey", lwd = 3)
plot(perflr, add = TRUE, col = "dodgerblue3", lwd = 3)
plot(perfnn, add=T, col = "aquamarine", lwd = 2)



aucct <- performance( predct, measure= "auc" )
aucct <- aucct@y.values[[1]]
formatC(aucct, digits = 2)

aucbag <- performance(predbag, "auc")
aucbag <- aucbag@y.values[[1]]
formatC(aucbag, digits = 2)

aucrf <- performance(predrf, "auc")
aucrf <- aucrf@y.values[[1]]
formatC(aucrf, digits = 2)

auclr <- performance(predlr, "auc")
auclr <- auclr@y.values[[1]]
formatC(auclr, digits = 2)

auclda <- performance(predlda, "auc")
auclda <- auclda@y.values[[1]]
formatC(auclda, digits = 2)

aucqda <- performance(predqda, "auc")
aucqda <- aucqda@y.values[[1]]
formatC(aucqda, digits = 2)

aucnn <- performance(prednn, "auc")
aucnn <- aucnn
formatC(aucnn, digits = 2)

#roc ve auc deÄŸerlere bakÄ±ldÄ±ÄŸÄ±nda en iyi sonuÃ§ veren modeller rf ve lr olarak saptanmÄ±ÅŸtÄ±r.

#kalp rahatsÄ±zlÄ±ÄŸÄ± sensivity kalp hastasÄ± olanlarÄ± kalp hastasÄ± olarak tahmin etme oranÄ±. Sensivity daha yÃ¼ksek olanÄ± sÄ±nÄ±flandrÄ±mak daha mantÄ±klÄ± kritik olduÄŸu iÃ§in sevs en y

